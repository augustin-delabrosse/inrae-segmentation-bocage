{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074ad39d-e4dc-4a41-8479-1ee4a54aec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from glob import glob\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug import parameters as iap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0731201-de38-43c9-a77c-1d1e65158c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess an image with histogram equalization\n",
    "def preprocess_image(image_path, mask_path):\n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(image_path)\n",
    "    mask_string = tf.io.read_file(mask_path)\n",
    "    # print(image_string, mask_string)\n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image_equalized = tf.numpy_function(equalize_histogram, [image_decoded], tf.float32)\n",
    "    \n",
    "    # Normalize the image\n",
    "    image_output = (image_equalized - tf.reduce_min(image_equalized)) / (tf.reduce_max(image_equalized) - tf.reduce_min(image_equalized))\n",
    "    \n",
    "    mask_decoded = tf.image.decode_jpeg(mask_string, channels=1)\n",
    "    \n",
    "    # Ensure mask_output is of type float32\n",
    "    mask_output = tf.cast(mask_decoded, tf.float32)\n",
    "    \n",
    "    return (image_output, mask_output)\n",
    "\n",
    "\n",
    "# Function to apply histogram equalization to an image\n",
    "def equalize_histogram(image):\n",
    "    # Convert RGB to YUV\n",
    "    image_yuv = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    # Apply histogram equalization to the Y channel\n",
    "    image_yuv[:,:,0] = cv2.equalizeHist(image_yuv[:,:,0])\n",
    "    # Convert YUV back to RGB\n",
    "    image_output = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
    "    image_output = tf.convert_to_tensor(image_output, dtype=tf.float32)\n",
    "    return image_output\n",
    "\n",
    "# Load your image and mask data\n",
    "image_path = 'vignettes/rgb\\\\rgb_305_6780\\\\rgb_35_305000_6780000.jpg'# 'vignettes/rgb/rgb_305_6785/rgb_35_305000_6781000.jpg'\n",
    "mask_path = 'vignettes/mask\\\\mask_305_6780\\\\mask_35_305000_6780000.png'\n",
    "\n",
    "# Preprocess the image and mask\n",
    "image, mask = preprocess_image(image_path, mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b048ea0-67ef-471a-abbf-e14146bc664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_histogram_tf(image):\n",
    "    # Convert RGB to YUV using TensorFlow\n",
    "    image_yuv = tf.image.rgb_to_yuv(image)\n",
    "    \n",
    "    # Extract the Y channel\n",
    "    y_channel = image_yuv[:, :, 0]\n",
    "    \n",
    "    # Normalize the Y channel to [0, 255]\n",
    "    y_channel = tf.cast(y_channel * 255.0, dtype=tf.uint8)\n",
    "    \n",
    "    # Apply histogram equalization using tf.image\n",
    "    y_channel_equalized = tf.image.equalize_hist(y_channel)\n",
    "    \n",
    "    # Convert the equalized Y channel back to [0, 1]\n",
    "    y_channel_equalized = tf.cast(y_channel_equalized, dtype=tf.float32) / 255.0\n",
    "    \n",
    "    # Replace the Y channel in the YUV image with the equalized Y channel\n",
    "    image_yuv_equalized = tf.stack([y_channel_equalized, image_yuv[:, :, 1], image_yuv[:, :, 2]], axis=-1)\n",
    "    \n",
    "    # Convert YUV back to RGB using TensorFlow\n",
    "    image_output = tf.image.yuv_to_rgb(image_yuv_equalized)\n",
    "    \n",
    "    return image_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf36ad35-7e7c-4087-b7fb-81bb08dfa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # Big enough to measure an F1-score\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n",
    "SHUFFLE_BUFFER_SIZE = 1024 # Shuffle the training data by a chunck of 1024 observations\n",
    "CHANNELS = 3\n",
    "IMG_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21235fa7-9ff6-4ba6-a9b2-845ee429d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img_paths = sorted(\n",
    "    list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [glob(i + \"*.jpg\") for i in glob(\"vignettes/rgb/*/\", recursive = True)]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "masks_img_paths = sorted(\n",
    "    list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [glob(i + \"*.png\") for i in glob(\"vignettes/mask/*/\", recursive = True)]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9369f3c1-0ba6-438c-991f-bdeb9964d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a first dataset of file paths and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((rgb_img_paths, masks_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa27e0de-f24f-4916-913d-da201fb068e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(preprocess_image, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f64bb68-5c9b-4591-9f21-414b4aaa7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = next(iter(dataset))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "358ccfe7-a72e-4c0c-9c89-bccc1bafa5d4",
   "metadata": {},
   "source": [
    "plt.imshow(elem[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9303eb22-0f06-44f8-a588-cd4e57542ad6",
   "metadata": {},
   "source": [
    "plt.imshow(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75a57554-9cab-4b03-b95a-e4582189009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply data augmentation to an image and its mask\n",
    "def augment_data(image, mask):\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.uint8)\n",
    "    \n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Crop(percent=(0, 0.3), keep_size=True),\n",
    "        iaa.Grayscale(alpha=iap.Choice([0, 1.0], p=[0.5, 0.5])),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.2))\n",
    "    ])\n",
    "    \n",
    "    aug_det = seq.to_deterministic()\n",
    "    image_aug = aug_det.augment_image(image.numpy())\n",
    "    mask_aug = aug_det.augment_image(mask.numpy())\n",
    "    \n",
    "    image_aug = tf.image.convert_image_dtype(image_aug, tf.float32)\n",
    "    mask_aug = tf.image.convert_image_dtype(mask_aug, tf.float32)\n",
    "    \n",
    "    return image_aug, mask_aug\n",
    "\n",
    "\n",
    "# Apply data augmentation\n",
    "image_aug, mask_aug = augment_data(elem[0], elem[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6606901d-abb4-4b33-bb53-49f7b50720be",
   "metadata": {},
   "source": [
    "plt.imshow(image_aug.numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b46811c-ab3d-4ff1-a489-1f8912cf5450",
   "metadata": {},
   "source": [
    "plt.imshow(mask_aug.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94603dae-c45f-45b5-a6a5-4c9e281bf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate new image and mask pairs\n",
    "def generate_new_data():\n",
    "    # You would implement this function to generate new image and mask pairs on-the-fly.\n",
    "    # For this example, let's create dummy data.\n",
    "    new_images = [tf.constant(image_aug)]\n",
    "    new_masks = [tf.constant(mask_aug)]\n",
    "\n",
    "    for image, mask in zip(new_images, new_masks):\n",
    "        yield image, mask\n",
    "\n",
    "# Create a dataset from the generator\n",
    "new_dataset = tf.data.Dataset.from_generator(\n",
    "    generate_new_data,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(288, 288, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(288, 288, 1), dtype=tf.float32),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a937049-337c-4f6b-94df-88c468bd9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_elem = next(iter(new_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0278b30-80f8-45a4-9d5d-97526200d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = dataset.concatenate(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4d5715b-64b1-496f-b48e-143046e53e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_elem = next(iter(combined_dataset))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17e21bac-ce15-4fcd-8a21-45b7db38be9b",
   "metadata": {},
   "source": [
    "plt.imshow(combined_elem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66531958-9104-4399-a8f9-a32f59aeed0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_elem = list(combined_dataset.as_numpy_iterator())[-1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35cd5d67-6f8f-47e4-8dcd-e9cdaef56188",
   "metadata": {},
   "source": [
    "plt.imshow(last_elem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9f2bc02-94d3-4e09-aa1b-47eab6de0814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1405"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(combined_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311075b-3973-4469-848f-ecd98dba0090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
